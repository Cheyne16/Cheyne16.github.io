<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>1-概率图模型 | Home</title><meta name=keywords content="ML,概率图模型，贝叶斯，马尔可夫，场"><meta name=description content="有向图模型（贝叶斯网络） 朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN
对于结点和边 y&ndash;>x，有 P(x|y)
依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——学习
通过联合概率分布，计算想要的条件概率——推断
无向图模型（马尔可夫网络） 马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）
利用极大团上的势函数定义概率分布：势能函数g + 能量函数E
马尔可夫随机场 && 条件随机场 马尔可夫随机场 MRF 条件随机场 CRF ？什么都没给出，所有结点平行 由观测变量推测标记变量（给定观测值的MRF） 模型 生成式（对联合概率建模），HMM也是 判别式（对条件概率建模） 图类型 无向图 <&mdash; 势函数 定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大 <&mdash; 利用团上的势函数定义 联合概率 条件概率 马尔可夫性概念区分 无向图中
全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。 成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。 有向图中
局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。 马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。 隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。 HMM关注的问题 推断问题：
推断观测序列的似然：计算$P(O|λ)$ 推断最可能的隐序列 推断现在 推断过去 推断未来 学习问题：
求模型参数 ：最大化给定观测序列出现的概率 精确推断 近似推断 变分推断 采样法 Sampling method 我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。
在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来估计分布参数的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来估计分布的期望、高阶动量等。其实在机器学习中，采样的主要用途是用来估计某个函数在某个分布上的期望 ，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。
也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。
对于简单的分布，直接随机采样或间接采样。
对于更复杂的分布："><meta name=author content="Chan"><link rel=canonical href=/posts/ml/1-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="1-概率图模型"><meta property="og:description" content="有向图模型（贝叶斯网络） 朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN
对于结点和边 y&ndash;>x，有 P(x|y)
依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——学习
通过联合概率分布，计算想要的条件概率——推断
无向图模型（马尔可夫网络） 马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）
利用极大团上的势函数定义概率分布：势能函数g + 能量函数E
马尔可夫随机场 && 条件随机场 马尔可夫随机场 MRF 条件随机场 CRF ？什么都没给出，所有结点平行 由观测变量推测标记变量（给定观测值的MRF） 模型 生成式（对联合概率建模），HMM也是 判别式（对条件概率建模） 图类型 无向图 <&mdash; 势函数 定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大 <&mdash; 利用团上的势函数定义 联合概率 条件概率 马尔可夫性概念区分 无向图中
全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。 成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。 有向图中
局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。 马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。 隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。 HMM关注的问题 推断问题：
推断观测序列的似然：计算$P(O|λ)$ 推断最可能的隐序列 推断现在 推断过去 推断未来 学习问题：
求模型参数 ：最大化给定观测序列出现的概率 精确推断 近似推断 变分推断 采样法 Sampling method 我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。
在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来估计分布参数的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来估计分布的期望、高阶动量等。其实在机器学习中，采样的主要用途是用来估计某个函数在某个分布上的期望 ，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。
也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。
对于简单的分布，直接随机采样或间接采样。
对于更复杂的分布："><meta property="og:type" content="article"><meta property="og:url" content="/posts/ml/1-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"><meta property="og:image" content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="og:site_name" content="Chancellor16's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="1-概率图模型"><meta name=twitter:description content="有向图模型（贝叶斯网络） 朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN
对于结点和边 y&ndash;>x，有 P(x|y)
依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——学习
通过联合概率分布，计算想要的条件概率——推断
无向图模型（马尔可夫网络） 马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）
利用极大团上的势函数定义概率分布：势能函数g + 能量函数E
马尔可夫随机场 && 条件随机场 马尔可夫随机场 MRF 条件随机场 CRF ？什么都没给出，所有结点平行 由观测变量推测标记变量（给定观测值的MRF） 模型 生成式（对联合概率建模），HMM也是 判别式（对条件概率建模） 图类型 无向图 <&mdash; 势函数 定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大 <&mdash; 利用团上的势函数定义 联合概率 条件概率 马尔可夫性概念区分 无向图中
全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。 成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。 有向图中
局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。 马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。 隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。 HMM关注的问题 推断问题：
推断观测序列的似然：计算$P(O|λ)$ 推断最可能的隐序列 推断现在 推断过去 推断未来 学习问题：
求模型参数 ：最大化给定观测序列出现的概率 精确推断 近似推断 变分推断 采样法 Sampling method 我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。
在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来估计分布参数的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来估计分布的期望、高阶动量等。其实在机器学习中，采样的主要用途是用来估计某个函数在某个分布上的期望 ，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。
也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。
对于简单的分布，直接随机采样或间接采样。
对于更复杂的分布："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"/posts/"},{"@type":"ListItem","position":3,"name":"1-概率图模型","item":"/posts/ml/1-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"1-概率图模型","name":"1-概率图模型","description":"有向图模型（贝叶斯网络） 朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN\n对于结点和边 y\u0026ndash;\u0026gt;x，有 P(x|y)\n依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——学习\n通过联合概率分布，计算想要的条件概率——推断\n无向图模型（马尔可夫网络） 马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）\n利用极大团上的势函数定义概率分布：势能函数g + 能量函数E\n马尔可夫随机场 \u0026amp;\u0026amp; 条件随机场 马尔可夫随机场 MRF 条件随机场 CRF ？什么都没给出，所有结点平行 由观测变量推测标记变量（给定观测值的MRF） 模型 生成式（对联合概率建模），HMM也是 判别式（对条件概率建模） 图类型 无向图 \u0026lt;\u0026mdash; 势函数 定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大 \u0026lt;\u0026mdash; 利用团上的势函数定义 联合概率 条件概率 马尔可夫性概念区分 无向图中\n全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。 成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。 有向图中\n局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。 马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。 隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。 HMM关注的问题 推断问题：\n推断观测序列的似然：计算$P(O|λ)$ 推断最可能的隐序列 推断现在 推断过去 推断未来 学习问题：\n求模型参数 ：最大化给定观测序列出现的概率 精确推断 近似推断 变分推断 采样法 Sampling method 我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。\n在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来估计分布参数的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来估计分布的期望、高阶动量等。其实在机器学习中，采样的主要用途是用来估计某个函数在某个分布上的期望 ，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。\n也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。\n对于简单的分布，直接随机采样或间接采样。\n对于更复杂的分布：","keywords":["ML","概率图模型，贝叶斯，马尔可夫，场"],"articleBody":" 有向图模型（贝叶斯网络） 朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN\n对于结点和边 y–\u003ex，有 P(x|y)\n依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——学习\n通过联合概率分布，计算想要的条件概率——推断\n无向图模型（马尔可夫网络） 马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）\n利用极大团上的势函数定义概率分布：势能函数g + 能量函数E\n马尔可夫随机场 \u0026\u0026 条件随机场 马尔可夫随机场 MRF 条件随机场 CRF ？什么都没给出，所有结点平行 由观测变量推测标记变量（给定观测值的MRF） 模型 生成式（对联合概率建模），HMM也是 判别式（对条件概率建模） 图类型 无向图 \u003c— 势函数 定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大 \u003c— 利用团上的势函数定义 联合概率 条件概率 马尔可夫性概念区分 无向图中\n全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。 成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。 有向图中\n局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。 马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。 隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。 HMM关注的问题 推断问题：\n推断观测序列的似然：计算$P(O|λ)$ 推断最可能的隐序列 推断现在 推断过去 推断未来 学习问题：\n求模型参数 ：最大化给定观测序列出现的概率 精确推断 近似推断 变分推断 采样法 Sampling method 我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。\n在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来估计分布参数的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来估计分布的期望、高阶动量等。其实在机器学习中，采样的主要用途是用来估计某个函数在某个分布上的期望 ，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。\n也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。\n对于简单的分布，直接随机采样或间接采样。\n对于更复杂的分布：\n拒绝采样(Rejection sampling) 重要性采样(Importance sampling) 马尔可夫链蒙特卡罗采样(Markov Chain Monte Carlo, MCMC) Metropolis-Hastings算法 Metropolis算法 Gibbs采样 拒绝采样 很多实际问题中，p(x)是很难直接采样的的，因此，我们需要求助其他的手段来采样。既然 p(x) 太复杂在程序中没法直接采样，那么我设定一个程序可抽样的分布 q(x) 比如高斯分布，然后按照一定的方法拒绝某些样本，达到接近 p(x) 分布的目的，其中q(x)叫做 proposal distribution（提议分布）\n设定一个方便抽样的函数 q(x)，以及一个常量 k，使得 p(x) 总在 kq(x) 的下方。\nx 轴方向：从 q(x) 分布抽样得到 a。(如果是高斯，就用之前说过的 tricky and faster 的算法更快） y 轴方向：从均匀分布（0, kq(a)) 中抽样得到 u。 如果刚好落到灰色区域： u \u003e p(a), 拒绝， 否则接受这次抽样 重复以上过程 在高维的情况下，Rejection Sampling 会出现两个问题，第一是合适的 q 分布比较难以找到，第二是很难确定一个合理的 k 值。这两个问题会导致拒绝率很高，无用计算增加。\n重要性采样 吉布斯采样 吉布斯采样（英语：Gibbs sampling）是统计学中用于马尔科夫蒙特卡洛（MCMC）的一种算法，用于在难以直接采样时从某一多变量概率分布中近似抽取样本序列。该序列可用于近似联合分布、部分变量的边缘分布或计算积分（如某一变量的期望值）。某些变量可能为已知变量，故对这些变量并不需要采样。\n吉布斯采样是一种简单且广泛适用的马尔可夫链蒙特卡洛（MCMC）算法，可以看作是MetropolisHastings算法的一个特例。吉布斯采样适用于联合分布未明确知道或难以直接抽样但每个变量的条件分布是已知的并且很容易（或者至少更容易）从中抽样的情况。\n考虑我们希望从中抽样的分布 $p(z)= p(z_1，…，z_M)$，并假设我们已经为马尔可夫链选择了一些初始状态。 吉布斯采样程序的每一步都涉及用某个变量相对于其他变量的条件概率分布中抽样得出的值代替该变量的值。即，我们用从分布 $p(z_i | z_{\\i})$ 绘制的值替换 $z_i$，其中$z_i$ 表示 z 的第i个分量，并且 $z_{\\i}$ 表示除 $z_i$ 以外的 $z_1，…，z_M$。如何我们通过以某种特定顺序循环变量或者通过从某个分布中随机选择每个步骤要更新的变量来重复该过程。\n举例来说，假设我们有三个变量的联合分布 $p(z_1，z_2，z_3)$，并且在算法的第 T 步中，我们已经抽取了$z_1^{(T)}$，$z_2^{(T)}$和 $z_3^{(T)}$。 我们首先将$z_1^{(T)}$替换为从条件分布中抽取的新值$z_1^{(T+1)}$，所使用的条件概率如下：\n同理，我们将$z_2^{(T)}$替换为从条件分布中抽取的值$z_2^{(T+1)}$:\n注意到在后续采样步骤中我们立即使用$z_1$的新值。\n然后我们用从中抽取的样本更新$z_3^{(T)}$得到$z_3^{(T+1)}$:\n这样依次循环三个变量，直到采样过程收敛，或达到循环次数上限。\n正式的吉布斯采样算法框架给定如下：\n吉布斯采样之所以被看作是Metropolis Hastings算法的一个特例，是因为它总是以1的概率接受抽样出的值，而Metropolis Hastings算法则以一定的概率拒绝或接受。\n【描述及图片来源：[Bishop C. M. (2006). Pattern Recognition and Machine Learning. Springer.](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop - Pattern Recognition And Machine Learning - Springer 2006.pdf)】\n进行抽样时：\n变量的初始值可以随机确定，也可以通过其他算法确定，例如期望最大化。 实际上不必确定采样的第一个变量的初始值。 通常在开始时忽略一些样本（所谓的老化期），然后利用n个样本的平均值以计算期望。例如，可能会忽略前1,000个样本，然后平均每100个样本，丢弃所有其余样本。其原因在于：（1）马尔可夫链的平稳分布是变量上所需的联合分布，但可能需要一段时间才能达到平稳分布;（2）连续样本不是彼此独立的，而是具有一定相关性的马尔可夫链。有时，可以使用算法来确定样本之间的自相关量和由此计算出的n值（实际使用的样本之间的周期），但在实践中有相当数量的“黑魔法”参与其中。 模拟退火过程通常用于减少采样过程早期的“随机游走”行为（即在样本空间周围缓慢移动的趋势，样本之间存在大量自相关，而不是如期望的那样快速移动 ）。减少自相关的技术：collapsed Gibbs sampling, blocked Gibbs sampling, ordered overrelaxation. 发展历史 吉布斯采样是以物理学家Josiah Willard Gibbs的名字命名的，他提到了采样算法和统计物理学之间的类比。Gibbs逝世后约八十年，Stuart和Donald Geman兄弟于1984年描述了该算法，这是我们目前熟悉的版本。1990年Alan E. Gelfand和 Adrian F. M. Smith对随机替换（Stochastic substitution），吉布斯采样（Gibbs sampler）和采样重要性重采样算法（sampling-importance-resampling algorithm）这三种重要的抽样算法进行了回顾和对比。\n由于EM算法是特别为了缺失数据而设计的，其与吉布斯采样之间有着天然的联系。1994年Jean Diebolt和Christian P. Robert提出了用于EM算法中M步的近似方法，其依赖于混合模型的缺失数据结构，通过吉布斯采样来评估后验分布和贝叶斯估计。\n吉布斯采样特别适合采样贝叶斯网络的后验分布，因为贝叶斯网络通常被指定为一组条件分布。\n在深度学习领域，Yoshua Bengio 等研究者最近提出了 GibbsNet，旨在通过匹配模型期望的联合分布和数据驱动的联合分布直接定义和学习转换算子（transition operator），然后使用转换算子训练图模型。这与无向图模型类似，也受到其启发，期望跃迁算子（对应成块吉布斯采样）沿着已定义能量流形移动，这样我们就可以在公式中建立该连接。\n主要事件 年份 事件 相关论文/Reference 1984 Stuart和Donald Geman兄弟描述了Gibbs抽样算法 Geman, S.; Geman, D.(1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.IEEE Transactions on Pattern Analysis and Machine Intelligence. 6 (6): 721–741. 1990 Alan E. Gelfand和 Adrian F. M. Smith对随机替换（Stochastic substitution），吉布斯采样（Gibbs sampler）和采样重要性重采样算法（sampling-importance-resampling algorithm）这三种重要的抽样算法进行了回顾和对比 Gelfand, A. E. and Smith, A. F. M. (1990). Sampling-based approaches to calculating marginal densities. J. Amer. Statist. Assoc. 85 398–409. 1994 Jean Diebolt和Christian P. Robert提出了用于EM算法中M步的近似方法 Diebolt, J. and Robert, C. P. (1994). Estimation of finite mixture distributions through Bayesian sampling. J. Roy. Statist. Soc. Ser. B 56 363–375. 2017 Yoshua Bengio 等研究者最近提出了 GibbsNet Lamb, A. et al. (2017).GibbsNet: Iterative Adversarial Inference for Deep Graphical Models.arXiv:1712.04120. 发展分析 瓶颈\n吉布斯采样仅要求使用者知道完全条件分布（full conditionals），但知道完全条件分布是非常重要的前提。如果使用者不知道完全条件分布或者不能有效地从该分布抽样，那么吉布斯采样要么不适用要么其表现不能与其他MCMC方法相比较。因此，吉布斯采样使用的范围是有限的，虽然在实际应用中许多使用者并不遵循这一点。\n未来发展方向\n吉布斯采样在许多领域都有应用，如主题模型、受限玻尔兹曼机（RBM），贝叶斯网络等，此外，Yoshua Bengio等学者提出了GibbsNet显示了即使在吉布斯采样还没有被应用的领域中，通过精巧的设计也可以将吉布斯采样算法融合，取得良好的效果。\nContributor：Yuanyuan Li\nref 吉布斯采样 | 机器之心 (jiqizhixin.com)\n","wordCount":"340","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Chan"},"mainEntityOfPage":{"@type":"WebPage","@id":"/posts/ml/1-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"},"publisher":{"@type":"Organization","name":"Home","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Cheyne16's Blog (Alt + H)"><img src=/apple-touch-icon.png alt aria-label=logo height=35>Cheyne16's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=/categories/ title=categories><span>categories</span></a></li><li><a href=/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/posts/>Posts</a></div><h1 class=post-title>1-概率图模型</h1><div class=post-meta>2 min&nbsp;·&nbsp;340 words&nbsp;·&nbsp;Chan&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/ML/1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p><img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220504134512453.png alt=image-20220504134512453></p><h1 id=有向图模型贝叶斯网络>有向图模型（贝叶斯网络）<a hidden class=anchor aria-hidden=true href=#有向图模型贝叶斯网络>#</a></h1><p>朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN</p><p>对于结点和边 y&ndash;>x，有 P(x|y)</p><p>依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——<strong>学习</strong></p><p>通过联合概率分布，计算想要的条件概率——<strong>推断</strong></p><h1 id=无向图模型马尔可夫网络>无向图模型（马尔可夫网络）<a hidden class=anchor aria-hidden=true href=#无向图模型马尔可夫网络>#</a></h1><p>马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）</p><p>利用极大团上的势函数定义概率分布：势能函数g + 能量函数E</p><h2 id=马尔可夫随机场--条件随机场>马尔可夫随机场 && 条件随机场<a hidden class=anchor aria-hidden=true href=#马尔可夫随机场--条件随机场>#</a></h2><table><thead><tr><th></th><th>马尔可夫随机场 MRF</th><th>条件随机场 CRF</th></tr></thead><tbody><tr><td></td><td>？什么都没给出，所有结点平行</td><td>由观测变量推测标记变量（给定观测值的MRF）</td></tr><tr><td>模型</td><td>生成式（对联合概率建模），HMM也是</td><td>判别式（对条件概率建模）</td></tr><tr><td>图类型</td><td>无向图</td><td>&lt;&mdash;</td></tr><tr><td>势函数</td><td>定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大</td><td>&lt;&mdash;</td></tr><tr><td>利用团上的势函数定义</td><td>联合概率<img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220501165501949.png alt=image-20220501165501949></td><td>条件概率<img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220501165540246.png alt=image-20220501165540246></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h1 id=马尔可夫性概念区分>马尔可夫性概念区分<a hidden class=anchor aria-hidden=true href=#马尔可夫性概念区分>#</a></h1><ul><li><p>无向图中</p><ul><li>全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。</li><li>局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。</li><li>成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。</li></ul></li><li><p>有向图中</p><ul><li>局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。</li><li>马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。<ul><li>隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。</li></ul></li></ul></li></ul><h1 id=hmm关注的问题>HMM关注的问题<a hidden class=anchor aria-hidden=true href=#hmm关注的问题>#</a></h1><p><img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220505101826134.png alt=image-20220505101826134></p><p>推断问题：</p><ul><li>推断观测序列的似然：计算$P(O|λ)$</li><li>推断最可能的隐序列</li><li>推断现在</li><li>推断过去</li><li>推断未来</li></ul><p>学习问题：</p><ul><li>求模型参数<img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220505101045157.png alt=image-20220505101045157>
：最大化给定观测序列出现的概率</li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220505102011470.png alt=image-20220505102011470></p><h1 id=精确推断>精确推断<a hidden class=anchor aria-hidden=true href=#精确推断>#</a></h1><h1 id=近似推断>近似推断<a hidden class=anchor aria-hidden=true href=#近似推断>#</a></h1><h2 id=变分推断>变分推断<a hidden class=anchor aria-hidden=true href=#变分推断>#</a></h2><h2 id=采样法-sampling-method>采样法 Sampling method<a hidden class=anchor aria-hidden=true href=#采样法-sampling-method>#</a></h2><p>我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。</p><p>在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来<strong>估计分布参数</strong>的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来<strong>估计分布的期望、高阶动量</strong>等。其实在机器学习中，采样的主要用途是用来<strong>估计某个函数在某个分布上的期望</strong> <img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220522194908012.png alt="image-20220522194908012 ">
，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。</p><p><img loading=lazy src=https://raw.githubusercontent.com/Cheyne16/ImageHub/main/image-20220522195318171.png alt=image-20220522195318171></p><p>也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。</p><p>对于简单的分布，直接随机采样或间接采样。</p><p>对于更复杂的分布：</p><ul><li>拒绝采样(Rejection sampling)</li><li>重要性采样(Importance sampling)</li><li>马尔可夫链蒙特卡罗采样(Markov Chain Monte Carlo, MCMC)<ul><li>Metropolis-Hastings算法</li><li>Metropolis算法</li><li>Gibbs采样</li></ul></li></ul><h3 id=拒绝采样>拒绝采样<a hidden class=anchor aria-hidden=true href=#拒绝采样>#</a></h3><p>很多实际问题中，p(x)是很难直接采样的的，因此，我们需要求助其他的手段来采样。既然 p(x) 太复杂在程序中没法直接采样，那么我设定一个程序可抽样的分布 q(x) 比如高斯分布，然后按照一定的方法拒绝某些样本，达到接近 p(x) 分布的目的，其中q(x)叫做 proposal distribution（提议分布）</p><p>设定一个方便抽样的函数 q(x)，以及一个常量 k，使得 p(x) 总在 kq(x) 的下方。</p><ul><li>x 轴方向：从 q(x) 分布抽样得到 a。(如果是高斯，就用之前说过的 tricky and faster 的算法更快）</li><li>y 轴方向：从均匀分布（0, kq(a)) 中抽样得到 u。</li><li>如果刚好落到灰色区域： u > p(a), 拒绝， 否则接受这次抽样</li><li>重复以上过程</li></ul><p>在高维的情况下，Rejection Sampling 会出现两个问题，第一是合适的 q 分布比较难以找到，第二是很难确定一个合理的 k 值。这两个问题会导致拒绝率很高，无用计算增加。</p><h3 id=重要性采样>重要性采样<a hidden class=anchor aria-hidden=true href=#重要性采样>#</a></h3><h3 id=吉布斯采样>吉布斯采样<a hidden class=anchor aria-hidden=true href=#吉布斯采样>#</a></h3><p>吉布斯采样（英语：Gibbs sampling）是统计学中用于马尔科夫蒙特卡洛（MCMC）的一种算法，用于在难以直接采样时从某一多变量概率分布中近似抽取样本序列。该序列可用于近似联合分布、部分变量的边缘分布或计算积分（如某一变量的期望值）。某些变量可能为已知变量，故对这些变量并不需要采样。</p><p>吉布斯采样是一种简单且广泛适用的马尔可夫链蒙特卡洛（MCMC）算法，可以看作是MetropolisHastings算法的一个特例。吉布斯采样适用于联合分布未明确知道或难以直接抽样但每个变量的条件分布是已知的并且很容易（或者至少更容易）从中抽样的情况。</p><p>考虑我们希望从中抽样的分布 $p(z)= p(z_1，&mldr;，z_M)$，并假设我们已经为马尔可夫链选择了一些初始状态。 吉布斯采样程序的每一步都涉及用某个变量相对于其他变量的条件概率分布中抽样得出的值代替该变量的值。即，我们用从分布 $p(z_i | z_{\i})$ 绘制的值替换 $z_i$，其中$z_i$ 表示 z 的第i个分量，并且 $z_{\i}$ 表示除 $z_i$ 以外的 $z_1，&mldr;，z_M$。如何我们通过以某种特定顺序循环变量或者通过从某个分布中随机选择每个步骤要更新的变量来重复该过程。</p><p>举例来说，假设我们有三个变量的联合分布 $p(z_1，z_2，z_3)$，并且在算法的第 T 步中，我们已经抽取了$z_1^{(T)}$，$z_2^{(T)}$和 $z_3^{(T)}$。 我们首先将$z_1^{(T)}$替换为从条件分布中抽取的新值$z_1^{(T+1)}$，所使用的条件概率如下：</p><p>同理，我们将$z_2^{(T)}$替换为从条件分布中抽取的值$z_2^{(T+1)}$:</p><p>注意到在后续采样步骤中我们立即使用$z_1$的新值。</p><p>然后我们用从中抽取的样本更新$z_3^{(T)}$得到$z_3^{(T+1)}$:</p><p>这样依次循环三个变量，直到采样过程收敛，或达到循环次数上限。</p><p>正式的吉布斯采样算法框架给定如下：</p><p>吉布斯采样之所以被看作是Metropolis Hastings算法的一个特例，是因为它总是以1的概率接受抽样出的值，而Metropolis Hastings算法则以一定的概率拒绝或接受。</p><p>【描述及图片来源：[Bishop C. M. (2006). Pattern Recognition and Machine Learning. Springer.](<a href=http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop>http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop</a> - Pattern Recognition And Machine Learning - Springer 2006.pdf)】</p><p>进行抽样时：</p><ol><li>变量的初始值可以随机确定，也可以通过其他算法确定，例如期望最大化。</li><li>实际上不必确定采样的第一个变量的初始值。</li><li>通常在开始时忽略一些样本（所谓的老化期），然后利用n个样本的平均值以计算期望。例如，可能会忽略前1,000个样本，然后平均每100个样本，丢弃所有其余样本。其原因在于：（1）马尔可夫链的平稳分布是变量上所需的联合分布，但可能需要一段时间才能达到平稳分布;（2）连续样本不是彼此独立的，而是具有一定相关性的马尔可夫链。有时，可以使用算法来确定样本之间的自相关量和由此计算出的n值（实际使用的样本之间的周期），但在实践中有相当数量的“黑魔法”参与其中。</li><li>模拟退火过程通常用于减少采样过程早期的“随机游走”行为（即在样本空间周围缓慢移动的趋势，样本之间存在大量自相关，而不是如期望的那样快速移动 ）。减少自相关的技术：collapsed Gibbs sampling, blocked Gibbs sampling, ordered overrelaxation.</li></ol><h4 id=发展历史>发展历史<a hidden class=anchor aria-hidden=true href=#发展历史>#</a></h4><p>吉布斯采样是以物理学家Josiah Willard Gibbs的名字命名的，他提到了采样算法和统计物理学之间的类比。Gibbs逝世后约八十年，Stuart和Donald Geman兄弟于1984年描述了该算法，这是我们目前熟悉的版本。1990年Alan E. Gelfand和 Adrian F. M. Smith对随机替换（Stochastic substitution），吉布斯采样（Gibbs sampler）和采样重要性重采样算法（sampling-importance-resampling algorithm）这三种重要的抽样算法进行了回顾和对比。</p><p>由于EM算法是特别为了缺失数据而设计的，其与吉布斯采样之间有着天然的联系。1994年Jean Diebolt和Christian P. Robert提出了用于EM算法中M步的近似方法，其依赖于混合模型的缺失数据结构，通过吉布斯采样来评估后验分布和贝叶斯估计。</p><p>吉布斯采样特别适合采样贝叶斯网络的后验分布，因为贝叶斯网络通常被指定为一组条件分布。</p><p>在深度学习领域，Yoshua Bengio 等研究者最近提出了 GibbsNet，旨在通过匹配模型期望的联合分布和数据驱动的联合分布直接定义和学习转换算子（transition operator），然后使用转换算子训练图模型。这与无向图模型类似，也受到其启发，期望跃迁算子（对应成块吉布斯采样）沿着已定义能量流形移动，这样我们就可以在公式中建立该连接。</p><h4 id=主要事件>主要事件<a hidden class=anchor aria-hidden=true href=#主要事件>#</a></h4><table><thead><tr><th>年份</th><th>事件</th><th>相关论文/Reference</th></tr></thead><tbody><tr><td>1984</td><td>Stuart和Donald Geman兄弟描述了Gibbs抽样算法</td><td>Geman, S.; Geman, D.(1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.IEEE Transactions on Pattern Analysis and Machine Intelligence. 6 (6): 721–741.</td></tr><tr><td>1990</td><td>Alan E. Gelfand和 Adrian F. M. Smith对随机替换（Stochastic substitution），吉布斯采样（Gibbs sampler）和采样重要性重采样算法（sampling-importance-resampling algorithm）这三种重要的抽样算法进行了回顾和对比</td><td>Gelfand, A. E. and Smith, A. F. M. (1990). Sampling-based approaches to calculating marginal densities. J. Amer. Statist. Assoc. 85 398–409.</td></tr><tr><td>1994</td><td>Jean Diebolt和Christian P. Robert提出了用于EM算法中M步的近似方法</td><td>Diebolt, J. and Robert, C. P. (1994). Estimation of finite mixture distributions through Bayesian sampling. J. Roy. Statist. Soc. Ser. B 56 363–375.</td></tr><tr><td>2017</td><td>Yoshua Bengio 等研究者最近提出了 GibbsNet</td><td>Lamb, A. et al. (2017).GibbsNet: Iterative Adversarial Inference for Deep Graphical Models.arXiv:1712.04120.</td></tr></tbody></table><h4 id=发展分析>发展分析<a hidden class=anchor aria-hidden=true href=#发展分析>#</a></h4><p>瓶颈</p><p>吉布斯采样仅要求使用者知道完全条件分布（full conditionals），但知道完全条件分布是非常重要的前提。如果使用者不知道完全条件分布或者不能有效地从该分布抽样，那么吉布斯采样要么不适用要么其表现不能与其他MCMC方法相比较。因此，吉布斯采样使用的范围是有限的，虽然在实际应用中许多使用者并不遵循这一点。</p><p>未来发展方向</p><p>吉布斯采样在许多领域都有应用，如主题模型、受限玻尔兹曼机（RBM），贝叶斯网络等，此外，Yoshua Bengio等学者提出了GibbsNet显示了即使在吉布斯采样还没有被应用的领域中，通过精巧的设计也可以将吉布斯采样算法融合，取得良好的效果。</p><p>Contributor：Yuanyuan Li</p><h1 id=ref>ref<a hidden class=anchor aria-hidden=true href=#ref>#</a></h1><p><a href=https://www.jiqizhixin.com/graph/technologies/672e5579-ffb9-4006-b5f8-7a9233f9c527>吉布斯采样 | 机器之心 (jiqizhixin.com)</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/ml/>ML</a></li><li><a href=/tags/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E8%B4%9D%E5%8F%B6%E6%96%AF%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%9C%BA/>概率图模型，贝叶斯，马尔可夫，场</a></li></ul><nav class=paginav><a class=prev href=/posts/nlp/chapter3-chinese-lexical-morphology/><span class=title>« Prev</span><br><span>Chapter3 - Chinese Lexical Morphology</span></a>
<a class=next href=/posts/ml/2-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/><span class=title>Next »</span><br><span>2-聚类分析</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 1-概率图模型 on twitter" href="https://twitter.com/intent/tweet/?text=1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b&url=%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f&hashtags=ML%2c%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b%ef%bc%8c%e8%b4%9d%e5%8f%b6%e6%96%af%ef%bc%8c%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%ef%bc%8c%e5%9c%ba"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 1-概率图模型 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f&title=1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b&summary=1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b&source=%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 1-概率图模型 on reddit" href="https://reddit.com/submit?url=%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f&title=1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 1-概率图模型 on facebook" href="https://facebook.com/sharer/sharer.php?u=%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 1-概率图模型 on whatsapp" href="https://api.whatsapp.com/send?text=1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b%20-%20%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 1-概率图模型 on telegram" href="https://telegram.me/share/url?text=1-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b&url=%2fposts%2fml%2f1-%25E6%25A6%2582%25E7%258E%2587%25E5%259B%25BE%25E6%25A8%25A1%25E5%259E%258B%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href>Home</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>