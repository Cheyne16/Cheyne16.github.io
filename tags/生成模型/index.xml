<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>生成模型 on Home</title>
    <link>/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 生成模型 on Home</description>
    <image>
      <title>Home</title>
      <url>%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator><atom:link href="/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>4-生成模型&#43;VAE</title>
      <link>/posts/ml/4-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B&#43;vae/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/ml/4-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B&#43;vae/</guid>
      <description>判别模型——给定X, Y，通过学习判别函数 f(x, y) 或 y = f(x) 来建模条件分布 P(Y|X)
​	——不能建模 P(X) 或 P(x, y)，所以不能生成新的X
生成模型——Y不是必须的。建模 P(x), P(x, y), P(X|Y)等，能生成新的X
如何构建生成模型：
显式密度估计：显式定义和求解p~model~(x)（最大似然估计法、近似法、马尔科夫链方法） 隐式密度估计：不显式定义p~model~(x)，而是学习一个可以从p~model~(x)中采样的模型，目标使X的采样概率似然最大 下面讲显式密度估计中的变分自动编码器，下次讲GAN
P(X)的极大似然估计 过程：采样$x_i$，计算概率$p(x_i)$，优化参数使概率 $\prod_{i}{}{p(x_i)}$ 最大
计算：通过log，推导得：最优参数=使原始分布和采样分布最接近（KL散度最小）的值
问题：在缺少领域知识的先验，对生成过程不了解时， 假设的分布基本都是错误的；如果选择的分布和真实分布不一致时，结果可 能很差；参数规模巨大，例如28 * 28维的手写数字，均值 和协方差的参数规模是784+784*784
解决方案：
引入隐变量模型，先找到一些要素z，然后再由z生成x。然后做MLE。
p(x|z; θ) 可以用 f(z, θ) 逼近，进而把概率密度 估计问题转化更加容易求解的函数逼近问题。
基本假设：任何一个概率分布经过一个足够复杂的函数后可以 映射到任意概率分布。
然而关于参数的梯度中分子分母中关于连续变量z的积分难以计算！
蒙特卡罗采样法 变分推断（VI）&amp;mdash;&amp;gt; VAE 变分自动编码器 Variational inference (VI)：机器学习中 ，变分推断是一种通过最优化的方 法近似估计概率的方法。VI背后的思想是提出一个分布家族，进一步从 中得到一个接近目标分布的分布，接近程度通 常用Kullback-Leibler散度计算
AutoEncoder：一种从无标记数据中，学习其低维特征表示的 无监督方法
基本思想 假设样本是从一个不可观测的隐变量z生成的，即
将直接求解p(x)化简为两步：
从先验分布 p~θ*~(z) 中抽样一个 z 从条件分布 p~θ*~(x|z^i^) 中抽样得到 x 目标：估计生成模型的真实参数 θ*</description>
    </item>
    
  </channel>
</rss>
