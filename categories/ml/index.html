<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ML | Home</title><meta name=keywords content><meta name=description content="This is Chancellor16's Blog"><meta name=author content="Chan"><link rel=canonical href=/categories/ml/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=/categories/ml/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="ML"><meta property="og:description" content="This is Chancellor16's Blog"><meta property="og:type" content="website"><meta property="og:url" content="/categories/ml/"><meta property="og:image" content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Chancellor16's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="ML"><meta name=twitter:description content="This is Chancellor16's Blog"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Cheyne16's Blog (Alt + H)"><img src=/apple-touch-icon.png alt aria-label=logo height=35>Cheyne16's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=/categories/ title=categories><span>categories</span></a></li><li><a href=/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/categories/>Categories</a></div><h1>ML
<a href=index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>1-概率图模型</h2></header><div class=entry-content><p>有向图模型（贝叶斯网络） 朴素贝叶斯分类器、隐马尔可夫模型HMM、深度信念网络DBN
对于结点和边 y–>x，有 P(x|y)
依据条件独立性假设，将联合概率分布分解成简单条件概率组合，从而求得联合概率分布——学习
通过联合概率分布，计算想要的条件概率——推断
无向图模型（马尔可夫网络） 马尔可夫随机场、条件随机场、玻尔兹曼机、对数线性模型（最大熵模型）
利用极大团上的势函数定义概率分布：势能函数g + 能量函数E
马尔可夫随机场 && 条件随机场 马尔可夫随机场 MRF 条件随机场 CRF ？什么都没给出，所有结点平行 由观测变量推测标记变量（给定观测值的MRF） 模型 生成式（对联合概率建模），HMM也是 判别式（对条件概率建模） 图类型 无向图 &lt;— 势函数 定义在（极大）团上，刻画团中变量的相关关系，在所偏好的变量取值上值较大 &lt;— 利用团上的势函数定义 联合概率 条件概率 马尔可夫性概念区分 无向图中
全局马尔可夫性：给定两个变量子集的分离集，则这两个子集条件独立。 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量。 成对马尔可夫性：给定所有其它变量，则两个非邻接变量条件独立。 有向图中
局部马尔可夫性：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。 马尔科夫链的马尔可夫性（也称服从马尔可夫假设）：某节点只与前面L个节点相关。 隐马尔可夫模型中的两个假设：（条件独立性假设）某一时刻的观测变量仅依赖于状态变量；（一阶马尔可夫假设）t+1时刻的状态变量仅依赖于 t 时刻的状态变量；前两条可推出第三条：观测变量是条件独立的。 HMM关注的问题 推断问题：
推断观测序列的似然：计算$P(O|λ)$ 推断最可能的隐序列 推断现在 推断过去 推断未来 学习问题：
求模型参数 ：最大化给定观测序列出现的概率 精确推断 近似推断 变分推断 采样法 Sampling method 我们知道了一个变量的分布，要生成一批样本服从这个分布，这个过程就叫采样。听起来好像很简单，对一些简单的分布函数确实如此，比如，均匀分布、正太分布，但只要分布函数稍微复杂一点，采样这个事情就没那么简单了。
在讲具体的采样方法之前，有必要弄清楚采样的目的。为什么要采样呢？有人可能会这样想，样本一般是用来估计分布参数的，现在我都知道分布函数了，还采样干嘛呢？其实采样不只是可以用来估计分布参数，还有其他用途，比如说用来估计分布的期望、高阶动量等。其实在机器学习中，采样的主要用途是用来估计某个函数在某个分布上的期望 ，比如在EM算法中，计算E步的时候，已知隐变量的分布，用采样的方法估计对数似然的期望。
也称为蒙特卡罗方法 (Monte Carlo method)，或统计模拟方法。
对于简单的分布，直接随机采样或间接采样。
对于更复杂的分布：...</p></div><footer class=entry-footer>2 min&nbsp;·&nbsp;340 words&nbsp;·&nbsp;Chan</footer><a class=entry-link aria-label="post link to 1-概率图模型" href=/posts/ml/1-%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>2-聚类分析</h2></header><div class=entry-content><p>有监督学习：分类、回归、目标检测、语义切分、图像描述。
无监督学习：学习关于数据的某种隐藏结构。聚类、特征降维、特征学习、密度估计。
聚类 类簇划分的角度：
良态可分类 基于最近邻的聚类 基于密度的聚类 基于中心点的聚类 基于共有属性或概念的聚类 聚类方法：
基于划分（Partitional Clustering） 基于层次（Hierarchical clustering） 自顶向下 自底向上 其它： 排它性聚类 vs. 非排它性聚类 模糊聚类 vs. 非模糊聚类 部分聚类 vs. 完全聚类 异构型聚类 vs. 同构型聚类 聚类模型 K-means 基于中心点
思想：类内距离最小化，类间距离最大化
算法过程：
假设有k个类簇，每个簇一个中心点(centriod)【中心点可看作有监督学习中的标签y】
将每个样本点划分到距离最近的中心点所属的簇中
迭代：
更新每个簇的中心点 然后重新划分 直到中心点不变
转换为有监督学习模型 目标函数：每个样本点与其簇中心点的距离之和。这里的距离可以是各种距离。
μk 表示簇Ck 的中心点（或其它能代表Ck的点） 若x~n~被划分到簇C~k~则r~nk~=1，否则r~nk~= 0 优化目标：找到簇的中心点μk及簇的划分r~nk~使得目标函数SSE最小
算法过程：
choose some initial values for the μ~k~ (k=1,…,K)
迭代：
minimize SSE with respect to the r~nk~ (n=1,…,N)
minimize SSE with respect to the m~k~...</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;156 words&nbsp;·&nbsp;Chan</footer><a class=entry-link aria-label="post link to 2-聚类分析" href=/posts/ml/2-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>3-特征降维和特征学习</h2></header><div class=entry-content><p>深度学习 &lt;— 无监督特征学习
介绍 特征是关于样本属性和特性的集中描述。多特征大样本提供了丰富的信息，然而
采集大规模数据往往很困难 一些特征区分样本的能力可能较差 一些特征之间可能存在相关性（房屋年龄、房屋新旧程度） 盲目减少特征可能损失很多信息 为什么要特征降维（特征选择）：发现主要的特征
为什么要特征学习：有效的表示特征
有哪些数学手段：
主成分分析（ Principle Component Analysis ） 独立成分分析（Independent Component Analysis） 线性判别分析（ Linear Discriminant Analysis） 等 PCA 通过特征值分解获取原始数据的新的特征或表示（主成分）：
是原始特征或表示的线性组合 彼此不相关（正交） 尽可能多地捕捉样本的原始方差 基本概念 方差、协方差：度量偏离均值的程度
方差：描述某一维度上的偏离程度
协方差：描述两个变量偏离各自均值的程度，从而表现其相关程度
协方差矩阵：描述多个变量。。。
步骤 结果：特征降维后得到正交的特征，且每一维的方差都很大
目标：寻找能够解释输入数据的方差的一组少量的正交的“方向”，将输入数据映射到这些“方向”上
假设：
数据是连续的（实际是离散的） 输入数据和学习得到的表示成线性关系 过程：
数据中心化（减去均值） 计算特征协方差矩阵C~d×d~ 计算C的m个最大特征值及其对应的特征向量~m×m~：得到m个主成分 Tips：通过np.linalg.eig计算得到的特征值并不是按照一定次序排列的，特征向量的每一列对应每一个特征值。 这些特征向量构成新的矩阵U~d×m~，进而将每一个d维的样本x映射到新的低维向量 z~m×1~ = U^T^~m×d~x~d×1~==（为什么不生成1×m的？一般的数据应该都是横向量吧？maybe：np.cov计算时默认每一行是一个属性，每一列是一个样本，可能这是规范形式）== 与SVD词向量分解不同之处：分解的原始矩阵不同，SVD是词共现矩阵。
两种证明思路 两种视角：最大化方差、最小化错误（等价的）
最大化方差 直觉：因为方差包含重要信息，所以希望降维后方差依然很大 计算：给定一个初始方向，计算样本点映射后的方差，优化方向使方差最大。 结果：公式推导可得，方差=协方差矩阵的特征值，所以，要使方差最大，应选择最大的特征值，用这些特征值对应的特征向量，构建新的正交基。有了正交基，即可计算样本点降维后的表示。 最小化错误（最小化重构误差） 基本思想：降维后的x与原来的x相差越小越好 计算：公式推导得，误差应取协方差矩阵的(d-m)个最小特征值的和 结果：构成主成分子空间的特征向量就是协方差矩阵的m个最大特征值所对应的特征向量 总结 简单有效
非线性问题PCA则无法发挥其作用
多数情况下，难以解释PCA所保持的主成分的意义
PCA将所有的样本作为一个整体对待，而忽略了类别属性
Autoencoder Autoencoder是一种采用无监督方式进行 特征学习的神经网络。...</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;111 words&nbsp;·&nbsp;Chan</footer><a class=entry-link aria-label="post link to 3-特征降维和特征学习" href=/posts/ml/3-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4%E5%92%8C%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>4-生成模型+VAE</h2></header><div class=entry-content><p>判别模型——给定X, Y，通过学习判别函数 f(x, y) 或 y = f(x) 来建模条件分布 P(Y|X)
​ ——不能建模 P(X) 或 P(x, y)，所以不能生成新的X
生成模型——Y不是必须的。建模 P(x), P(x, y), P(X|Y)等，能生成新的X
如何构建生成模型：
显式密度估计：显式定义和求解p~model~(x)（最大似然估计法、近似法、马尔科夫链方法） 隐式密度估计：不显式定义p~model~(x)，而是学习一个可以从p~model~(x)中采样的模型，目标使X的采样概率似然最大 下面讲显式密度估计中的变分自动编码器，下次讲GAN
P(X)的极大似然估计 过程：采样$x_i$，计算概率$p(x_i)$，优化参数使概率 $\prod_{i}{}{p(x_i)}$ 最大
计算：通过log，推导得：最优参数=使原始分布和采样分布最接近（KL散度最小）的值
问题：在缺少领域知识的先验，对生成过程不了解时， 假设的分布基本都是错误的；如果选择的分布和真实分布不一致时，结果可 能很差；参数规模巨大，例如28 * 28维的手写数字，均值 和协方差的参数规模是784+784*784
解决方案：
引入隐变量模型，先找到一些要素z，然后再由z生成x。然后做MLE。
p(x|z; θ) 可以用 f(z, θ) 逼近，进而把概率密度 估计问题转化更加容易求解的函数逼近问题。
基本假设：任何一个概率分布经过一个足够复杂的函数后可以 映射到任意概率分布。
然而关于参数的梯度中分子分母中关于连续变量z的积分难以计算！
蒙特卡罗采样法 变分推断（VI）—> VAE 变分自动编码器 Variational inference (VI)：机器学习中 ，变分推断是一种通过最优化的方 法近似估计概率的方法。VI背后的思想是提出一个分布家族，进一步从 中得到一个接近目标分布的分布，接近程度通 常用Kullback-Leibler散度计算
AutoEncoder：一种从无标记数据中，学习其低维特征表示的 无监督方法
基本思想 假设样本是从一个不可观测的隐变量z生成的，即
将直接求解p(x)化简为两步：
从先验分布 p~θ*~(z) 中抽样一个 z 从条件分布 p~θ*~(x|z^i^) 中抽样得到 x 目标：估计生成模型的真实参数 θ*...</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;119 words&nbsp;·&nbsp;Chan</footer><a class=entry-link aria-label="post link to 4-生成模型+VAE" href=/posts/ml/4-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B+vae/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>5-GAN</h2></header><div class=entry-content><p>VAE与GAN：
Generative：学习一个生成模型
Adversarial：在对抗学习的设置下训练模型
Networks：深度神经网络
对抗学习的思想 对抗学习是一种机器学习领域常用的学习策略， 通过引入假样本迷惑模型（增强模型的鲁棒性、 降低过拟合）
一般实现方式：
构造对抗任务：生成对抗样本以迷惑判别模型（★★★） 促使模型在完成主任务的时候，同时完成对抗任务 重复训练过程，提升判别模型的学习能力 GAN的基本思想 GANs 将上述思想拓展到生成模型，基本思想是训练两个网络：生成器和判别器，二者对抗训练，获得更好的生成器和判别器。
GAN组织结构 整体结构：
Z 是样本的隐变量表示，也被称为随机噪声。
训练过程：将生成的样本和真实样本一起交给判别器做判断，误差反传轮流更新判别器参数和生成器参数：
最终，通过充分训练，渴望算法收敛于一个好的关于数据分布的估计p~g~，即由它生成的样本无法被判别器清楚分辨是真是假。同时，训练出一个好的判别器D，即给定任意的生成器G，训练判别器D的标准是最大化V (G, D) 。
具体代价函数 判别器 判别器是一个分类器，试图为生成的数据输出0，为真实的数据输出1，min代价函数：
生成器 生成器希望判别器输出为1，min代价函数：
极大极小博弈（minimax game） 生成器和判别器之间互为对抗的零和博弈 （zero-sum game）</p></div><footer class=entry-footer>1 min&nbsp;·&nbsp;34 words&nbsp;·&nbsp;Chan</footer><a class=entry-link aria-label="post link to 5-GAN" href=/posts/ml/5-gan/></a></article><footer class=page-footer><nav class=pagination><a class=next href=/categories/ml/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href>Home</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>